{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55863fad-718d-4a06-b59f-8e4de3712c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79651c9b-366d-4027-99f3-0b3515fb34c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fasthtml.common import *\n",
    "from monsterui.all import *\n",
    "from fasthtml.jupyter import *\n",
    "from fastcore.utils import *\n",
    "import os\n",
    "import sqlite_utils\n",
    "import llm \n",
    "import os\n",
    "import threading\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import argparse\n",
    "\n",
    "if not in_notebook():\n",
    "    parser = argparse.ArgumentParser(description='CounciLLM - Query multiple LLMs simultaneously')\n",
    "    parser.add_argument('-n', type=int, default=6, help='Number of models to query')\n",
    "    parser.add_argument('--no-logging', action='store_true', help='Start with logging toggled off')\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Update constants based on command line arguments\n",
    "    N_MODELS = args.n\n",
    "    START_WITH_LOGGING = not args.no_logging\n",
    "else:\n",
    "    N_MODELS = 6\n",
    "    START_WITH_LOGGING = True\n",
    "    \n",
    "thread_local = threading.local()\n",
    "\n",
    "MODELS = {'gpt-4o': 'gpt 4o', 'gemini-2.0-flash-thinking-exp-01-21': 'Gemini 2.0 Thinking',\n",
    "          'claude-3.7-sonnet': 'Claude 3.7 Sonnet', 'deepseek-chat': 'DeepSeek Chat', 'groq-llama-3.3-70b': 'LLama 3.3 70b', \n",
    "          'claude-3.5-haiku': 'Claude 3.5 Haiku', 'deepseek-reasoner': 'Deepseek Reasoner', 'claude-3.5-sonnet': 'Claude 3.5 Sonnet', \n",
    "          'gemini-2.0-flash-exp': 'Gemini 2.0 Flash', 'gemini-2.0-pro-exp-02-05': 'Gemini 2.0 Pro', \n",
    "          'groq/deepseek-r1-distill-llama-70b': 'Groq DeepSeek LLama', 'groq-mixtral': 'Mixtral', \n",
    "          '4o-mini': 'GPT 4o-mini', 'deepseek-coder': 'Deepseek Coder'\n",
    "         }\n",
    "\n",
    "app,rt,tcs,ThreadConversation = fast_app(\n",
    "    'data/threads.db',\n",
    "    hdrs=Theme.blue.headers(),\n",
    "    id=int, name=str, tid=int, cid=str, mn=str, mid=str, rid=str, when=datetime, pk='id',\n",
    "    live=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0dc85a-35b3-484b-8da9-fbe3bd9be2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<script>\n",
       "document.body.addEventListener('htmx:configRequest', (event) => {\n",
       "    if(event.detail.path.includes('://')) return;\n",
       "    htmx.config.selfRequestsOnly=false;\n",
       "    event.detail.path = `${location.protocol}//${location.hostname}:8000${event.detail.path}`;\n",
       "});\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "server = JupyUvi(app)\n",
    "Show = partialler(HTMX, app=app, link=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff70467e-8e51-4c9d-9cf1-4300fe9486a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_llm_db():\n",
    "    if os.environ.get(\"LLM_USER_PATH\") is not None:\n",
    "        if not hasattr(thread_local, \"db\"):\n",
    "            thread_local.db = sqlite_utils.Database(Path(os.environ[\"LLM_USER_PATH\"]) / \"logs.db\")\n",
    "    else:\n",
    "        if not hasattr(thread_local, \"db\"):\n",
    "            thread_local.db =  sqlite_utils.Database(llm.user_dir() / \"logs.db\")\n",
    "    return thread_local.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe25d58c-ee4c-4312-8480-1c78db6f04b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class LoggedChat(BasicRepr):\n",
    "    def __init__(self, tid:int, mn:str, include=True, may_log=True, p:str=None, sp:str=None, m=None, c=None): \n",
    "        store_attr()\n",
    "        self.m = llm.get_model(self.mn)\n",
    "        self.c = self.m.conversation()\n",
    "\n",
    "    def prompt(self, tid, mid, p, sp=None):\n",
    "        global tcs, l\n",
    "        self.p = p\n",
    "        self.sp = sp\n",
    "        r = self.c.prompt(p, system=sp)\n",
    "        if isinstance(r, Exception):\n",
    "            return r\n",
    "        if self.may_log:\n",
    "            db = get_llm_db()\n",
    "            try:\n",
    "                r.log_to_db(db)\n",
    "                rid = first(db.execute(\"SELECT MAX(id) FROM responses WHERE conversation_id=?\", self.c.id))['id']\n",
    "                tcs.insert(tid=tid, cid=self.c.id, mn=self.mn, mid=mid, rid=rid, when=datetime.now().isoformat())\n",
    "            except Exception as e:\n",
    "                return e\n",
    "        else:\n",
    "            # need to iterate the response so that it gets added to conversation\n",
    "            for _ in r:\n",
    "                pass\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07a784d-d2fd-41f9-bbdd-cad0885f6e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dum/miniforge3/envs/LLM/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "\n",
    "lcs = [LoggedChat(tid=1, mn=k, include=True, may_log=START_WITH_LOGGING) for i, k in enumerate(MODELS) if i < N_MODELS]\n",
    "\n",
    "def model_selector(tid=1):\n",
    "    model_controls = []\n",
    "    \n",
    "    for i, model in enumerate([lc.mn for lc in lcs], start=1):\n",
    "        # Create a column for each model with dropdown and switch\n",
    "        model_column = Div(\n",
    "            # Model dropdown\n",
    "            Select(\n",
    "                *[Option(MODELS[m], value=m, selected=(m==model)) for m in MODELS],\n",
    "                id=f'model_{i}',\n",
    "                name=\"model\",\n",
    "                cls=\"w-full mb-2\",\n",
    "                **{\n",
    "                    \"hx-post\": f\"/update_model/{tid}/{i}\",\n",
    "                    \"hx-trigger\": f\"click from:#model_{i} .uk-drop-close\",\n",
    "                    \"hx-target\": f\"#model_feedback_{i}\",\n",
    "                    \"hx-swap\": \"innerHTML\",\n",
    "                    \"hx-include\": f\"#model_{i},#may_log\"\n",
    "                }\n",
    "            ),\n",
    "            Div(id=f\"model_feedback_{i}\", cls=\"text-xs mb-2\"),  # Feedback area\n",
    "            DivRAligned(\n",
    "                LabelSwitch(\n",
    "                    label=\"Include\", \n",
    "                    id=f'switch_{i}',\n",
    "                    checked=lcs[i-1].include,\n",
    "                    cls=\"mt-2\",\n",
    "                    **{\n",
    "                        \"hx-post\": f\"/toggle_model/{i}\",\n",
    "                        \"hx-trigger\": \"change\",\n",
    "                        \"hx-target\": f\"#switch_feedback_{i}\",\n",
    "                        \"hx-swap\": \"innerHTML\",\n",
    "                        \"hx-include\": f\"#switch_{i}\"\n",
    "                    }\n",
    "                ),\n",
    "                A(UkIcon(\"download\"),\n",
    "                       alt=\"Download recent for this model\",\n",
    "                       href=f\"/download/{tid}/ALL/{i-1}\",\n",
    "                       cls=\"uk-button uk-button-link\"),                  \n",
    "            ),\n",
    "            Div(id=f\"switch_feedback_{i}\", cls=\"text-xs\"),  # Switch feedback area\n",
    "            \n",
    "            cls=\"px-2 text-center\"\n",
    "        )\n",
    "        model_controls.append(model_column)\n",
    "    \n",
    "    return Div(\n",
    "        *model_controls,\n",
    "        cls=\"flex justify-between mb-4\"\n",
    "    )\n",
    "    \n",
    "@rt(\"/update_model/{tid}/{idx}\")\n",
    "async def update_model(tid:int, idx: int, model: str, request: Request):\n",
    "    global lcs\n",
    "    print(model)\n",
    "    form_data = await request.form()\n",
    "    lcs[idx-1] = LoggedChat(tid=tid, mn=model, include=lcs[idx-1].include, may_log=(form_data.get(f\"may_log\") == \"on\"))\n",
    "    # Return visual feedback\n",
    "    return Div(\n",
    "        MODELS[model], \n",
    "        cls=\"text-success text-xs mt-1 transition-opacity duration-1000 opacity-100\",\n",
    "        _=\"on load wait 1s then add .opacity-0\"\n",
    "    )\n",
    "\n",
    "@rt(\"/toggle_model/{idx}\")\n",
    "async def toggle_model(idx: int, request: Request):\n",
    "    global lcs\n",
    "    form_data = await request.form()\n",
    "    lcs[idx-1].include = (form_data.get(f\"switch_{idx}\") == \"on\")\n",
    "    status = \"enabled\" if lcs[idx-1].include else \"disabled\"\n",
    "    # Return visual feedback\n",
    "    return Div(\n",
    "        f\"Model {status}\", \n",
    "        cls=f\"text-{'success' if lcs[idx-1].include else 'warning'} text-xs mt-1 transition-opacity duration-1000 opacity-100\",\n",
    "        _=\"on load wait 1s then add .opacity-0\"\n",
    "    )\n",
    "    \n",
    "@rt(\"/toggle_logging\")\n",
    "async def toggle_logging(request: Request):\n",
    "    global lcs\n",
    "    form_data = await request.form()\n",
    "    for lc in lcs:\n",
    "        lc.may_log = (form_data.get(f\"may_log\") == \"on\")\n",
    "    status = \"enabled\" if (form_data.get(f\"may_log\") == \"on\") else \"disabled\"\n",
    "    # Return visual feedback\n",
    "    return Div(\n",
    "        f\"Logging {status}\", \n",
    "        cls=f\"text-success text-xs mt-1 transition-opacity duration-1000 opacity-100\",\n",
    "        _=\"on load wait 1s then add .opacity-0\"\n",
    "    )\n",
    "\n",
    "def prompt_form(thread_id=1, message_id=1):\n",
    "    return Div(\n",
    "        Form(\n",
    "            TextArea(\n",
    "                placeholder=\"Enter your prompt here...\",\n",
    "                cls=\"w-full h-40\",\n",
    "                id=\"main_prompt\",\n",
    "                name=\"main_prompt\"\n",
    "            ),\n",
    "            Button(\n",
    "                \"Submit\",\n",
    "                cls=\"btn btn-primary mt-2\",\n",
    "                id=\"submit_button\",\n",
    "                **{\n",
    "                    \"hx-post\": f\"/responses/{thread_id}/{message_id}\",\n",
    "                    \"hx-target\": \"#responses_container\",\n",
    "                    \"hx-swap\": \"afterbegin\",\n",
    "                    \"hx-include\": \"#system_prompt,#main_prompt\",\n",
    "                    \"hx-swap-oob\": \"true\",\n",
    "                    \"hx-disabled-elt\": \"this\"\n",
    "                }\n",
    "            ),\n",
    "            Script(\"\"\"\n",
    "                me().on(\"keydown\", ev => {\n",
    "                    if (ev.ctrlKey && ev.key === \"Enter\") {\n",
    "                        halt(ev);\n",
    "                        any(\"#submit_button\").send(\"click\");\n",
    "                    }\n",
    "                })\n",
    "            \"\"\"),\n",
    "            id=\"prompt_form\",\n",
    "            cls=\"mb-4\",\n",
    "            hx_swap_oob=\"true\",            \n",
    "            _=\"on htmx:afterSwap remove me\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "def input_section(thread_id=1, message_id=1):\n",
    "    selector = model_selector(thread_id)\n",
    "    system_prompt = Div(\n",
    "        Details(\n",
    "            Summary(\"System Prompt\"),\n",
    "            TextArea(\n",
    "                placeholder=\"Enter system prompt here...\",\n",
    "                cls=\"w-full h-32\",\n",
    "                id=\"system_prompt\",\n",
    "                name=\"system_prompt\"\n",
    "            ),\n",
    "            cls=\"mb-4\"\n",
    "        )\n",
    "    )\n",
    "    may_log = (\n",
    "                LabelSwitch(\n",
    "                    label=\"Log Responses\", \n",
    "                    id=f'may_log',\n",
    "                    checked=START_WITH_LOGGING,\n",
    "                    cls=\"mt-2\",\n",
    "                    **{\n",
    "                        \"hx-post\": f\"/toggle_logging\",\n",
    "                        \"hx-trigger\": \"change\",\n",
    "                        \"hx-target\": f\"#logging_feedback\",\n",
    "                        \"hx-swap\": \"innerHTML\",\n",
    "                        \"hx-include\": f\"#may_log\"\n",
    "                    }\n",
    "                ),\n",
    "                Div(id=f\"logging_feedback\", cls=\"text-xs\"),  # Switch feedback area\n",
    "            )\n",
    "    prompt_area = prompt_form(thread_id, message_id)\n",
    "\n",
    "    return selector, Hr(), system_prompt, Hr(), prompt_area, *may_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00d7325-2298-4007-a1d4-0dd15bce51c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def display_system_prompt(thread_id=1, message_id=1, sp=\"\"):\n",
    "    return H6(\"System Prompt:\", cls=\"font-semibold mb-2\"), Div(sp, id=f\"system_prompt_{thread_id}_{message_id}\", cls=\"mb-4 p-2 border rounded\"),\n",
    "\n",
    "def display_user_prompt(thread_id=1, message_id=1, p=\"\"):\n",
    "    return H6(\"User Prompt:\", cls=\"font-semibold mb-2\"), Div(p, id=f\"user_prompt_{thread_id}_{message_id}\", cls=\"mb-4 p-2 border rounded\")\n",
    "\n",
    "@rt(\"/download/{thread_id}/{message_id}/{i}/{j}\")\n",
    "def download_response(thread_id: int, message_id: int, i: int, j: int):\n",
    "    content = f\"\"\"Prompt: {str(lcs[i].c.responses[j].prompt.prompt)}\n",
    "----\n",
    "Reponse:\n",
    "{str(lcs[i].c.responses[j])}\"\"\"\n",
    "    filename = f\"response_{thread_id}_{message_id}_{lcs[i].mn}_{datetime.now():%Y%m%d_%H%M}.txt\"\n",
    "    headers = {\n",
    "        \"Content-Disposition\": f\"attachment; filename={filename}\",\n",
    "        \"Content-Type\": \"text/plain\"\n",
    "    }\n",
    "    return Response(content=content, headers=headers)\n",
    "\n",
    "\n",
    "@rt(\"/download/{thread_id}/ALL/{i}\")\n",
    "def download_response(thread_id: int, i: int):\n",
    "    content = \"\"\n",
    "    for r in lcs[i].c.responses:\n",
    "        content = content + f\"\"\"Prompt: {r.prompt.prompt}\n",
    "----\n",
    "Response:\n",
    "{str(r)}\n",
    "\n",
    "----\n",
    "\"\"\"\n",
    "    filename = f\"response_{thread_id}_{lcs[i].mn}_{datetime.now():%Y%m%d_%H%M}.txt\"\n",
    "    headers = {\n",
    "        \"Content-Disposition\": f\"attachment; filename={filename}\",\n",
    "        \"Content-Type\": \"text/plain\"\n",
    "    }\n",
    "    return Response(content=content, headers=headers)\n",
    "\n",
    "def model_header(name, response_id, thread_id: int, message_id: int, i: int, result, timestamp=None):\n",
    "    if timestamp is None:\n",
    "        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    copy_script = \"\"\"\n",
    "    async function copyFormatted(id) {\n",
    "        const content = document.getElementById(id);\n",
    "        try {\n",
    "            await navigator.clipboard.write([\n",
    "                new ClipboardItem({\n",
    "                    'text/html': new Blob([content.innerHTML], {type: 'text/html'}),\n",
    "                    'text/plain': new Blob([content.innerText], {type: 'text/plain'})\n",
    "                })\n",
    "            ]);\n",
    "        } catch (err) {\n",
    "            console.error('Failed to copy: ', err);\n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    return Div(\n",
    "        Script(copy_script),\n",
    "        H5(\n",
    "            Div(\n",
    "                Div(name, cls=\"flex-grow text-center\"),\n",
    "                Button(UkIcon(\"clipboard\"), \n",
    "                      onclick=f\"copyFormatted('{response_id}')\",\n",
    "                      cls=\"float-right\"),\n",
    "                A(UkIcon(\"download\"),\n",
    "                       href=f\"/download/{thread_id}/{message_id}/{i}/{len(lcs[i].c.responses)-1}\",\n",
    "                       cls=\"uk-button uk-button-link\") if not isinstance(result, Exception) else None,\n",
    "                cls=\"flex justify-between items-center w-full\",\n",
    "            ),\n",
    "            title=timestamp,\n",
    "            cls=TextT.center,\n",
    "        ),\n",
    "        Hr(),\n",
    "    )\n",
    "\n",
    "@rt(\"/responses/{thread_id}/{message_id}\")\n",
    "def message_response(thread_id:int=1, message_id:int=1, main_prompt:str=\"\", system_prompt:str=None):\n",
    "    global lcs, MODELS, N_MODELS\n",
    "\n",
    "    def run_prompts(lc): lc.prompt(thread_id, message_id, main_prompt, system_prompt) if lc.include else None\n",
    "        \n",
    "    with ThreadPool(len(lcs)) as pool:\n",
    "        rs = pool.map(run_prompts, lcs)\n",
    "\n",
    "    response_div = Div(\n",
    "        Details(\n",
    "            Summary(f\"Prompts given (Message {message_id})\"),\n",
    "            Div(\n",
    "                *display_system_prompt(sp=system_prompt) if system_prompt is not None and system_prompt.strip() != \"\" else (),\n",
    "                *display_user_prompt(p=main_prompt) if main_prompt is not None and main_prompt.strip() != \"\" else (),\n",
    "                cls=\"bg-neutral-content space-y-2\"\n",
    "            ),\n",
    "            cls=\"mb-4\",\n",
    "            open=True\n",
    "        ),\n",
    "        *[Div(\n",
    "            model_header(MODELS[lc.mn], f\"response_{(message_id * N_MODELS) - i}\", thread_id, message_id, i, rs[i]),\n",
    "            Div(render_md(str(lc.c.responses[-1])), id=f\"response_{(message_id * N_MODELS) - i}\", cls=\"mb-8\") \\\n",
    "                if not isinstance(rs[i], Exception) else \\\n",
    "            Div(str(rs[i]), id=f\"response_{(message_id * N_MODELS) - i}\", cls=\"bg-warning mb-8\") \\\n",
    "        ) for i, lc in enumerate(lcs) if lc.include],\n",
    "        **{\n",
    "            \"hx-swap\": \"afterbegin\",\n",
    "            \"hx-target\": \"#responses_container\"\n",
    "        }\n",
    "    ),\n",
    "    new_form = prompt_form(thread_id, message_id + 1)\n",
    "\n",
    "    return response_div, new_form\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc39cb59-779a-42a1-abc8-a1e34aa26d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@rt('/')\n",
    "def index(thread_id=1, message_id=1):\n",
    "    return Title(\"CounciLLMs\"), Div(input_section(), Div(id=\"responses_container\", cls=\"space-y-4\"), Script(\"\"\"htmx.on(\"htxm:afterRequest\", function(evt) {\n",
    "    console.log(\"HTMX Request completed:\", evt);\n",
    "));\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0371a992-7d39-46cc-9e62-5da689aa4adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"http://localhost:8000/_aWH4CiUeQymaUo1hnz50ng\" target=\"_blank\">Open in new tab</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe src=\"http://localhost:8000/_aWH4CiUeQymaUo1hnz50ng\" style=\"width: 100%; height: auto; border: none;\" onload=\"{\n",
       "        let frame = this;\n",
       "        window.addEventListener('message', function(e) {\n",
       "            if (e.source !== frame.contentWindow) return; // Only proceed if the message is from this iframe\n",
       "            if (e.data.height) frame.style.height = (e.data.height+1) + 'px';\n",
       "        }, false);\n",
       "    }\" allow=\"accelerometer; autoplay; camera; clipboard-read; clipboard-write; display-capture; encrypted-media; fullscreen; gamepad; geolocation; gyroscope; hid; identity-credentials-get; idle-detection; magnetometer; microphone; midi; payment; picture-in-picture; publickey-credentials-get; screen-wake-lock; serial; usb; web-share; xr-spatial-tracking\"></iframe> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Show(Div(input_section()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1cf45d-a035-4e72-8485-ed8c5785c3f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"http://localhost:8000/_Ab4OQUDFTbGWRqnk2-JniA\" target=\"_blank\">Open in new tab</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe src=\"http://localhost:8000/_Ab4OQUDFTbGWRqnk2-JniA\" style=\"width: 100%; height: auto; border: none;\" onload=\"{\n",
       "        let frame = this;\n",
       "        window.addEventListener('message', function(e) {\n",
       "            if (e.source !== frame.contentWindow) return; // Only proceed if the message is from this iframe\n",
       "            if (e.data.height) frame.style.height = (e.data.height+1) + 'px';\n",
       "        }, false);\n",
       "    }\" allow=\"accelerometer; autoplay; camera; clipboard-read; clipboard-write; display-capture; encrypted-media; fullscreen; gamepad; geolocation; gyroscope; hid; identity-credentials-get; idle-detection; magnetometer; microphone; midi; payment; picture-in-picture; publickey-credentials-get; screen-wake-lock; serial; usb; web-share; xr-spatial-tracking\"></iframe> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Show(message_response(thread_id=1, message_id=1, main_prompt=\"Please tell me a short joke?\", system_prompt=\"You are a fan of walruses\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89253a1-a36d-4338-8a32-0d767d2b7c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "serve()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
